{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2736653-8b65-43f2-a46d-c511ca2b595a",
   "metadata": {},
   "source": [
    "# Chapter 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06703e7-dd63-4a39-a29b-70d78193002e",
   "metadata": {},
   "source": [
    "## 5.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ddc596e-24f3-4bfa-ada0-47d3263f1d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis Test, H=15.898631510783048, p=6.682701971781596e-05\n",
      "Mann-Whitney U-test, U=6508.0, p=6.717710120362762e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np    # A\n",
    "from scipy import stats as st\n",
    "\n",
    "group_a = st.skewnorm.rvs(a=9, scale=2.2, size=99) + 4.5    # B\n",
    "group_b = st.skewnorm.rvs(a=11, scale=1, size=99) + 4.6\n",
    "\n",
    "H = st.kruskal(group_a, group_b)    # C\n",
    "U = st.mannwhitneyu(group_a, group_b)\n",
    "\n",
    "print(f\"Kruskal-Wallis Test, H={H[0]}, p={H[1]}\")   # D\n",
    "print(f\"Mann-Whitney U-test, U={U[0]}, p={U[1]}\")\n",
    "\n",
    "#A Import libraries\n",
    "#B Generate two skewed distributions\n",
    "#C Run a Kruskal-Wallis and Mann-Whitney U-test\n",
    "#D Print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1455af5-665b-4640-8a55-6fc2e649efd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis Test, H=9.483119607834055, p=0.0020737104811859686\n",
      "          1         2         3\n",
      "1  1.000000  0.006403  1.000000\n",
      "2  0.006403  1.000000  0.095883\n",
      "3  1.000000  0.095883  1.000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # A\n",
    "from scipy import stats as st\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "group_a = st.skewnorm.rvs(a=9, scale=2.2, size=99) + 4.6  # B\n",
    "group_b = st.skewnorm.rvs(a=11, scale=1.5, size=99) + 4.6\n",
    "group_c = st.skewnorm.rvs(a=9.1, scale=2.0, size=99) + 4.6\n",
    "\n",
    "data = [group_a, group_b, group_c]\n",
    "H = st.kruskal(group_a, group_b)  # C\n",
    "post_hoc = sp.posthoc_dunn(data, p_adjust=\"bonferroni\")\n",
    "\n",
    "print(f\"Kruskal-Wallis Test, H={H[0]}, p={H[1]}\")  # D\n",
    "print(post_hoc)\n",
    "\n",
    "#A Import libraries\n",
    "#B Generate three non-normal series of data\n",
    "#C Perform a Kruskal-Wallis test and a Dunn test as a post-hoc\n",
    "#D Print the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68119a9f-346b-4586-a902-2dca89ecb338",
   "metadata": {},
   "source": [
    "## 5.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "212de694-3b42-4ec7-9dd5-65d0a1ffc4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st    #A\n",
    "\n",
    "chi_sq = st.chi2_contingency(assignments)    #B\n",
    "\n",
    "print(f\"Chi-square value: {chi_sq[0].round(3)}\")    #C\n",
    "print(f\"p-value: {chi_sq[1].round(3)}\")\n",
    "print(f\"Expected Frequencies:\\n {chi_sq[3].round(2)}\")\n",
    "\n",
    "#A Import the stats library from scipy\n",
    "#B Conduct the chi-square test\n",
    "#C Print results\n",
    "#D Chi-square test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "636c6224-96a9-4e31-b108-3ff5b4fbb769",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = assignments * .2596    #A\n",
    "print(expected)    #B\n",
    "\n",
    "#A Calculate expected frequencies based on the total proportion\n",
    "#B Show expected proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5daa5e85-0e70-4cfb-a47e-c830349552e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_sq = st.chi2_contingency(clicked.iloc[:-1, :-1], expected)    #A\n",
    "\n",
    "print(f\"Chi-square value: {chi_sq[0].round(3)}\")    #B\n",
    "print(f\"p-value: {chi_sq[1].round(3)}\")\n",
    "\n",
    "#A Calculate a chi-square test \n",
    "#B Print resulting test statistic and p-value\n",
    "#C Test statistic results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5029c061-3a46-4203-a99c-9e3ff836ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns    #A\n",
    "from operator import sub\n",
    "\n",
    "diffs = list(map(sub, clicked.values, expected.values))    #B\n",
    "diffs = pd.DataFrame(\n",
    "    diffs,\n",
    "    columns=assignments.columns,\n",
    "    index=assignments.index,\n",
    ")\n",
    "sns.heatmap(  # C\n",
    "    diffs.iloc[:-1, :-1],\n",
    "    cmap=\"vlag\",\n",
    "    annot=True,\n",
    "    cbar=False,\n",
    ") \n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Recommender Version\")\n",
    "\n",
    "#A Import Seaborn and the subtraction operator\n",
    "#B Subtract corresponding values between each item in the observed and expected frequencies\n",
    "#C Convert the differences to a heatmap for a more presentable display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6005542a-5a0b-4680-b363-c28a1428df1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations  # A\n",
    "\n",
    "pairs = list(combinations(assigned.iloc[:-1, :-1].index, 2))  # B\n",
    "chisq_values = []\n",
    "p_values = []\n",
    "\n",
    "for p in pairs:  # C\n",
    "    c = clicked[(clicked.index == p[0]) | (clicked.index == p[1])]\n",
    "    chi2, pv, dof, exp = st.chi2_contingency(c, correction=True)\n",
    "    chisq_values.append(chi2)\n",
    "    p_values.append(pv)\n",
    "    print(p, pv.round(3))    #D\n",
    "\n",
    "#A Import combinations function\n",
    "#B Generate pairs of experiment groups and empty lists\n",
    "#C Conduct a chi-square test with a correction for each pairwise comparison of experiment groups\n",
    "#D Print each pair and its corresponding p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5fdd67-93df-4224-b964-3f6b0c68e495",
   "metadata": {},
   "source": [
    "## 5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29731868-aa1a-4edd-bade-ca42619036c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # A\n",
    "from scipy import stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X1 = np.random.normal(loc=75.5, scale=6.2, size=500)  # B\n",
    "X2 = np.random.normal(loc=76.2, scale=6.5, size=500)\n",
    "\n",
    "def t_stat(X1, X2):  # C\n",
    "    return st.ttest_ind(X1, X2)[0]\n",
    "\n",
    "t_values = st.bootstrap(  # D\n",
    "    (X1, X2),\n",
    "    t_stat,\n",
    "    n_resamples=1000,\n",
    "    batch=50,\n",
    "    method=\"basic\",\n",
    "    vectorized=False,\n",
    "    random_state=99,\n",
    ")\n",
    "\n",
    "t_crit = -st.t.ppf(q=0.95, df=49)  # E\n",
    "\n",
    "plt.hist(result.bootstrap_distribution, bins=25)  # F\n",
    "plt.axvline(t_crit, color=\"black\", linestyle=\"dashed\")\n",
    "\n",
    "#A Import libraries\n",
    "#B Generate two normal distributions for independent t-test comparisons\n",
    "#C Create a function to return only the t-value from a an independent samples t-test\n",
    "#D Calculate bootstrapped t-values with 1000 samples of n=50\n",
    "#E Calculate the (negative) t-critical value \n",
    "#F Plot the distribution with the critical value as a vertical line"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
